<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title>Test Report</title>
    <link href="assets/style.css" rel="stylesheet" type="text/css"/></head>
  <body onLoad="init()">
    <script>/* This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this file,
 * You can obtain one at http://mozilla.org/MPL/2.0/. */


function toArray(iter) {
    if (iter === null) {
        return null;
    }
    return Array.prototype.slice.call(iter);
}

function find(selector, elem) { // eslint-disable-line no-redeclare
    if (!elem) {
        elem = document;
    }
    return elem.querySelector(selector);
}

function findAll(selector, elem) {
    if (!elem) {
        elem = document;
    }
    return toArray(elem.querySelectorAll(selector));
}

function sortColumn(elem) {
    toggleSortStates(elem);
    const colIndex = toArray(elem.parentNode.childNodes).indexOf(elem);
    let key;
    if (elem.classList.contains('result')) {
        key = keyResult;
    } else if (elem.classList.contains('links')) {
        key = keyLink;
    } else {
        key = keyAlpha;
    }
    sortTable(elem, key(colIndex));
}

function showAllExtras() { // eslint-disable-line no-unused-vars
    findAll('.col-result').forEach(showExtras);
}

function hideAllExtras() { // eslint-disable-line no-unused-vars
    findAll('.col-result').forEach(hideExtras);
}

function showExtras(colresultElem) {
    const extras = colresultElem.parentNode.nextElementSibling;
    const expandcollapse = colresultElem.firstElementChild;
    extras.classList.remove('collapsed');
    expandcollapse.classList.remove('expander');
    expandcollapse.classList.add('collapser');
}

function hideExtras(colresultElem) {
    const extras = colresultElem.parentNode.nextElementSibling;
    const expandcollapse = colresultElem.firstElementChild;
    extras.classList.add('collapsed');
    expandcollapse.classList.remove('collapser');
    expandcollapse.classList.add('expander');
}

function showFilters() {
    const filterItems = document.getElementsByClassName('filter');
    for (let i = 0; i < filterItems.length; i++)
        filterItems[i].hidden = false;
}

function addCollapse() {
    // Add links for show/hide all
    const resulttable = find('table#results-table');
    const showhideall = document.createElement('p');
    showhideall.innerHTML = '<a href="javascript:showAllExtras()">Show all details</a> / ' +
                            '<a href="javascript:hideAllExtras()">Hide all details</a>';
    resulttable.parentElement.insertBefore(showhideall, resulttable);

    // Add show/hide link to each result
    findAll('.col-result').forEach(function(elem) {
        const collapsed = getQueryParameter('collapsed') || 'Passed';
        const extras = elem.parentNode.nextElementSibling;
        const expandcollapse = document.createElement('span');
        if (extras.classList.contains('collapsed')) {
            expandcollapse.classList.add('expander');
        } else if (collapsed.includes(elem.innerHTML)) {
            extras.classList.add('collapsed');
            expandcollapse.classList.add('expander');
        } else {
            expandcollapse.classList.add('collapser');
        }
        elem.appendChild(expandcollapse);

        elem.addEventListener('click', function(event) {
            if (event.currentTarget.parentNode.nextElementSibling.classList.contains('collapsed')) {
                showExtras(event.currentTarget);
            } else {
                hideExtras(event.currentTarget);
            }
        });
    });
}

function getQueryParameter(name) {
    const match = RegExp('[?&]' + name + '=([^&]*)').exec(window.location.search);
    return match && decodeURIComponent(match[1].replace(/\+/g, ' '));
}

function init () { // eslint-disable-line no-unused-vars
    resetSortHeaders();

    addCollapse();

    showFilters();

    sortColumn(find('.initial-sort'));

    findAll('.sortable').forEach(function(elem) {
        elem.addEventListener('click',
            function() {
                sortColumn(elem);
            }, false);
    });
}

function sortTable(clicked, keyFunc) {
    const rows = findAll('.results-table-row');
    const reversed = !clicked.classList.contains('asc');
    const sortedRows = sort(rows, keyFunc, reversed);
    /* Whole table is removed here because browsers acts much slower
     * when appending existing elements.
     */
    const thead = document.getElementById('results-table-head');
    document.getElementById('results-table').remove();
    const parent = document.createElement('table');
    parent.id = 'results-table';
    parent.appendChild(thead);
    sortedRows.forEach(function(elem) {
        parent.appendChild(elem);
    });
    document.getElementsByTagName('BODY')[0].appendChild(parent);
}

function sort(items, keyFunc, reversed) {
    const sortArray = items.map(function(item, i) {
        return [keyFunc(item), i];
    });

    sortArray.sort(function(a, b) {
        const keyA = a[0];
        const keyB = b[0];

        if (keyA == keyB) return 0;

        if (reversed) {
            return keyA < keyB ? 1 : -1;
        } else {
            return keyA > keyB ? 1 : -1;
        }
    });

    return sortArray.map(function(item) {
        const index = item[1];
        return items[index];
    });
}

function keyAlpha(colIndex) {
    return function(elem) {
        return elem.childNodes[1].childNodes[colIndex].firstChild.data.toLowerCase();
    };
}

function keyLink(colIndex) {
    return function(elem) {
        const dataCell = elem.childNodes[1].childNodes[colIndex].firstChild;
        return dataCell == null ? '' : dataCell.innerText.toLowerCase();
    };
}

function keyResult(colIndex) {
    return function(elem) {
        const strings = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed',
            'Skipped', 'Passed'];
        return strings.indexOf(elem.childNodes[1].childNodes[colIndex].firstChild.data);
    };
}

function resetSortHeaders() {
    findAll('.sort-icon').forEach(function(elem) {
        elem.parentNode.removeChild(elem);
    });
    findAll('.sortable').forEach(function(elem) {
        const icon = document.createElement('div');
        icon.className = 'sort-icon';
        icon.textContent = 'vvv';
        elem.insertBefore(icon, elem.firstChild);
        elem.classList.remove('desc', 'active');
        elem.classList.add('asc', 'inactive');
    });
}

function toggleSortStates(elem) {
    //if active, toggle between asc and desc
    if (elem.classList.contains('active')) {
        elem.classList.toggle('asc');
        elem.classList.toggle('desc');
    }

    //if inactive, reset all other functions and add ascending active
    if (elem.classList.contains('inactive')) {
        resetSortHeaders();
        elem.classList.remove('inactive');
        elem.classList.add('active');
    }
}

function isAllRowsHidden(value) {
    return value.hidden == false;
}

function filterTable(elem) { // eslint-disable-line no-unused-vars
    const outcomeAtt = 'data-test-result';
    const outcome = elem.getAttribute(outcomeAtt);
    const classOutcome = outcome + ' results-table-row';
    const outcomeRows = document.getElementsByClassName(classOutcome);

    for(let i = 0; i < outcomeRows.length; i++){
        outcomeRows[i].hidden = !elem.checked;
    }

    const rows = findAll('.results-table-row').filter(isAllRowsHidden);
    const allRowsHidden = rows.length == 0 ? true : false;
    const notFoundMessage = document.getElementById('not-found-message');
    notFoundMessage.hidden = !allRowsHidden;
}
</script>
    <h1>pytest_report.html</h1>
    <p>Report generated on 12-Aug-2022 at 14:52:31 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a> v3.1.1</p>
    <h2>Environment</h2>
    <table id="environment">
      <tr>
        <td>Packages</td>
        <td>{"pluggy": "1.0.0", "py": "1.11.0", "pytest": "7.1.2"}</td></tr>
      <tr>
        <td>Platform</td>
        <td>Linux-5.15.32-0-virt-aarch64-with-glibc2.31</td></tr>
      <tr>
        <td>Plugins</td>
        <td>{"anyio": "3.6.1", "benchmark": "3.4.1", "cov": "3.0.0", "forked": "1.4.0", "html": "3.1.1", "lazy-fixture": "0.6.3", "metadata": "2.0.2", "mock": "1.10.4", "ordering": "0.6", "timeout": "1.4.2", "typeguard": "2.13.3", "xdist": "2.5.0"}</td></tr>
      <tr>
        <td>Python</td>
        <td>3.10.6</td></tr></table>
    <h2>Summary</h2>
    <p>62 tests ran in 88.51 seconds. </p>
    <p class="filter" hidden="true">(Un)check the boxes to filter the results.</p><input checked="true" class="filter" data-test-result="passed" hidden="true" name="filter_checkbox" onChange="filterTable(this)" type="checkbox"/><span class="passed">45 passed</span>, <input checked="true" class="filter" data-test-result="skipped" hidden="true" name="filter_checkbox" onChange="filterTable(this)" type="checkbox"/><span class="skipped">18 skipped</span>, <input checked="true" class="filter" data-test-result="failed" hidden="true" name="filter_checkbox" onChange="filterTable(this)" type="checkbox"/><span class="failed">17 failed</span>, <input checked="true" class="filter" data-test-result="error" hidden="true" name="filter_checkbox" onChange="filterTable(this)" type="checkbox"/><span class="error">4 errors</span>, <input checked="true" class="filter" data-test-result="xfailed" disabled="true" hidden="true" name="filter_checkbox" onChange="filterTable(this)" type="checkbox"/><span class="xfailed">0 expected failures</span>, <input checked="true" class="filter" data-test-result="xpassed" disabled="true" hidden="true" name="filter_checkbox" onChange="filterTable(this)" type="checkbox"/><span class="xpassed">0 unexpected passes</span>
    <h2>Results</h2>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable result initial-sort" col="result">Result</th>
          <th class="sortable" col="name">Test</th>
          <th class="sortable" col="duration">Duration</th>
          <th class="sortable links" col="links">Links</th></tr>
        <tr hidden="true" id="not-found-message">
          <th colspan="4">No results found. Try to check the filters</th></tr></thead>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/integration/e2e/test_go_feature_server.py::collect</td>
          <td class="col-duration"></td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">ImportError while importing test module &#x27;/root/feast/sdk/python/tests/integration/e2e/test_go_feature_server.py&#x27;.<br/>Hint: make sure your test modules/packages have valid Python names.<br/>Traceback:<br/>/usr/local/lib/python3.10/importlib/__init__.py:126: in import_module<br/>    return _bootstrap._gcd_import(name[level:], package, level)<br/>sdk/python/tests/integration/e2e/test_go_feature_server.py:12: in &lt;module&gt;<br/>    from feast.embedded_go.online_features_service import EmbeddedOnlineFeatureServer<br/>sdk/python/feast/embedded_go/online_features_service.py:22: in &lt;module&gt;<br/>    from .lib.embedded import (<br/><span class="error">E   ModuleNotFoundError: No module named &#x27;feast.embedded_go.lib&#x27;</span><br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/integration/e2e/test_python_feature_server.py::test_get_online_features[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]::setup</td>
          <td class="col-duration">0.20</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_5aa615_1&#x27;, test_repo_config=LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_f...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffff64e378b0&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...object at 0xffff64e1f910&gt;, field_mapping=&lt;feast.infra.offline_stores.file_source.FileSource object at 0xffff64e1f970&gt;))<br/>request = &lt;SubRequest &#x27;python_fs_client&#x27; for &lt;Function test_get_online_features[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]&gt;&gt;<br/><br/>    @pytest.fixture<br/>    def python_fs_client(environment, universal_data_sources, request):<br/>        fs = environment.feature_store<br/>        entities, datasets, data_sources = universal_data_sources<br/>        feature_views = construct_universal_feature_views(data_sources)<br/>        feast_objects: List[FeastObject] = []<br/>        feast_objects.extend(feature_views.values())<br/>        feast_objects.extend([driver(), customer(), location()])<br/>&gt;       fs.apply(feast_objects)<br/><br/>sdk/python/tests/integration/e2e/test_python_feature_server.py:111: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffff64c5e6b0&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff83951870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/integration/e2e/test_python_feature_server.py::test_push[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]::setup</td>
          <td class="col-duration">0.21</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_74d246_1&#x27;, test_repo_config=LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_f...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffff44667a30&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...object at 0xffff4445ba90&gt;, field_mapping=&lt;feast.infra.offline_stores.file_source.FileSource object at 0xffff4445bfa0&gt;))<br/>request = &lt;SubRequest &#x27;python_fs_client&#x27; for &lt;Function test_push[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]&gt;&gt;<br/><br/>    @pytest.fixture<br/>    def python_fs_client(environment, universal_data_sources, request):<br/>        fs = environment.feature_store<br/>        entities, datasets, data_sources = universal_data_sources<br/>        feature_views = construct_universal_feature_views(data_sources)<br/>        feast_objects: List[FeastObject] = []<br/>        feast_objects.extend(feature_views.values())<br/>        feast_objects.extend([driver(), customer(), location()])<br/>&gt;       fs.apply(feast_objects)<br/><br/>sdk/python/tests/integration/e2e/test_python_feature_server.py:111: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffff4448e830&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff631c9870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/integration/online_store/test_universal_online.py::test_online_retrieval_success[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]::setup</td>
          <td class="col-duration">0.08</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>request = &lt;FixtureRequest for &lt;Function test_online_retrieval_success[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]&gt;&gt;<br/><br/>    def fill(request):<br/>        item = request._pyfuncitem<br/>        fixturenames = getattr(item, &quot;fixturenames&quot;, None)<br/>        if fixturenames is None:<br/>            fixturenames = request.fixturenames<br/>    <br/>        if hasattr(item, &#x27;callspec&#x27;):<br/>            for param, val in sorted_by_dependency(item.callspec.params, fixturenames):<br/>                if val is not None and is_lazy_fixture(val):<br/>                    item.callspec.params[param] = request.getfixturevalue(val.name)<br/>                elif param not in item.funcargs:<br/>&gt;                   item.funcargs[param] = request.getfixturevalue(param)<br/><br/>/usr/local/lib/python3.10/site-packages/pytest_lazyfixture.py:37: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/tests/conftest.py:400: in feature_store_for_online_retrieval<br/>    fs.apply(feast_objects)<br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffff828065c0&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff67a31870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/e2e/test_validation.py::test_historical_retrieval_fails_on_validation[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">0.10</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_9cf82c_1&#x27;, test_repo_config=LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_f...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffff444f5ae0&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...object at 0xffff41095e40&gt;, field_mapping=&lt;feast.infra.offline_stores.file_source.FileSource object at 0xffff41095cc0&gt;))<br/><br/>    @pytest.mark.integration<br/>    def test_historical_retrieval_fails_on_validation(environment, universal_data_sources):<br/>        store = environment.feature_store<br/>    <br/>        (entities, datasets, data_sources) = universal_data_sources<br/>        feature_views = construct_universal_feature_views(data_sources)<br/>    <br/>&gt;       store.apply([driver(), customer(), location(), *feature_views.values()])<br/><br/>sdk/python/tests/integration/e2e/test_validation.py:83: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffff444fb6d0&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff631c9870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/offline_store/test_feature_logging.py::test_feature_service_logging[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-True]</td>
          <td class="col-duration">20.32</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw6] linux -- Python 3.10.6 /usr/local/bin/python[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_9c0c9f_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffff7932c7c0&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...ld_mapping=&lt;feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource object at 0xffffb86fc1f0&gt;))<br/>pass_as_path = True<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    @pytest.mark.parametrize(&quot;pass_as_path&quot;, [True, False], ids=lambda v: str(v))<br/>    def test_feature_service_logging(environment, universal_data_sources, pass_as_path):<br/>        store = environment.feature_store<br/>    <br/>        (_, datasets, data_sources) = universal_data_sources<br/>    <br/>        feature_views = construct_universal_feature_views(data_sources)<br/>&gt;       store.apply([customer(), driver(), location(), *feature_views.values()])<br/><br/>sdk/python/tests/integration/offline_store/test_feature_logging.py:37: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffffb85e4eb0&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff97f4d870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/08/12 14:51:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory
Scaling row group sizes to 95.00% for 8 writers
<br/> -----------------------------Captured stderr setup------------------------------ <br/>Warning: Ignoring non-Spark config property: master
Setting default log level to &quot;WARN&quot;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:=======&gt;                                                   (1 + 7) / 8]                                                                                [Stage 1:==============&gt;                                            (2 + 6) / 8]                                                                                [Stage 2:=======&gt;                                                   (1 + 7) / 8][Stage 2:=============================&gt;                             (4 + 4) / 8]                                                                                [Stage 3:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 4:====================================&gt;                      (5 + 3) / 8]                                                                                [Stage 5:&gt;                                                          (0 + 8) / 8][Stage 5:============================================&gt;              (6 + 2) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/offline_store/test_feature_logging.py::test_feature_service_logging[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-False]</td>
          <td class="col-duration">20.32</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_f1430f_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffff70a63400&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...ld_mapping=&lt;feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource object at 0xffffaa5e1c60&gt;))<br/>pass_as_path = False<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    @pytest.mark.parametrize(&quot;pass_as_path&quot;, [True, False], ids=lambda v: str(v))<br/>    def test_feature_service_logging(environment, universal_data_sources, pass_as_path):<br/>        store = environment.feature_store<br/>    <br/>        (_, datasets, data_sources) = universal_data_sources<br/>    <br/>        feature_views = construct_universal_feature_views(data_sources)<br/>&gt;       store.apply([customer(), driver(), location(), *feature_views.values()])<br/><br/>sdk/python/tests/integration/offline_store/test_feature_logging.py:37: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffffaa53d960&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff8f5c1870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/08/12 14:51:13 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory
Scaling row group sizes to 95.00% for 8 writers
<br/> -----------------------------Captured stderr setup------------------------------ <br/>Warning: Ignoring non-Spark config property: master
Setting default log level to &quot;WARN&quot;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 1:&gt;                                                          (0 + 8) / 8][Stage 1:============================================&gt;              (6 + 2) / 8]                                                                                [Stage 2:=======&gt;                                                   (1 + 7) / 8][Stage 2:==============&gt;                                            (2 + 6) / 8][Stage 2:======================&gt;                                    (3 + 5) / 8]                                                                                [Stage 3:&gt;                                                          (0 + 8) / 8][Stage 3:==============&gt;                                            (2 + 6) / 8]                                                                                [Stage 4:============================================&gt;              (6 + 2) / 8]                                                                                [Stage 5:&gt;                                                          (0 + 8) / 8][Stage 5:======================&gt;                                    (3 + 5) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/e2e/test_validation.py::test_historical_retrieval_with_validation[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">21.67</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw0] linux -- Python 3.10.6 /usr/local/bin/python[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_fd48ef_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffff64c5f910&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...ld_mapping=&lt;feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource object at 0xffff5c528550&gt;))<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    def test_historical_retrieval_with_validation(environment, universal_data_sources):<br/>        store = environment.feature_store<br/>        (entities, datasets, data_sources) = universal_data_sources<br/>        feature_views = construct_universal_feature_views(data_sources)<br/>&gt;       store.apply([driver(), customer(), location(), *feature_views.values()])<br/><br/>sdk/python/tests/integration/e2e/test_validation.py:48: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffff5c52bca0&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff83951870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/08/12 14:51:14 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:14 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:14 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:51:14 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
22/08/12 14:51:22 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory
Scaling row group sizes to 95.00% for 8 writers
<br/> -----------------------------Captured stderr setup------------------------------ <br/>Warning: Ignoring non-Spark config property: master
Setting default log level to &quot;WARN&quot;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 1:&gt;                                                          (0 + 8) / 8][Stage 1:=======&gt;                                                   (1 + 7) / 8][Stage 1:============================================&gt;              (6 + 2) / 8]                                                                                [Stage 2:&gt;                                                          (0 + 8) / 8][Stage 2:===================================================&gt;       (7 + 1) / 8]                                                                                [Stage 3:&gt;                                                          (0 + 8) / 8][Stage 3:==============&gt;                                            (2 + 6) / 8]                                                                                [Stage 4:=============================&gt;                             (4 + 4) / 8][Stage 4:============================================&gt;              (6 + 2) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/offline_store/test_universal_historical_retrieval.py::test_historical_features[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-full:False]</td>
          <td class="col-duration">7.44</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_a7e8d3_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffff828f66e0&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...ld_mapping=&lt;feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource object at 0xffff82852770&gt;))<br/>full_feature_names = False<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    @pytest.mark.parametrize(&quot;full_feature_names&quot;, [True, False], ids=lambda v: f&quot;full:{v}&quot;)<br/>    def test_historical_features(environment, universal_data_sources, full_feature_names):<br/>        store = environment.feature_store<br/>    <br/>        (entities, datasets, data_sources) = universal_data_sources<br/>    <br/>        feature_views = construct_universal_feature_views(data_sources)<br/>    <br/>        entity_df_with_request_data = datasets.entity_df.copy(deep=True)<br/>        entity_df_with_request_data[&quot;val_to_add&quot;] = [<br/>            i for i in range(len(entity_df_with_request_data))<br/>        ]<br/>        entity_df_with_request_data[&quot;driver_age&quot;] = [<br/>            i + 100 for i in range(len(entity_df_with_request_data))<br/>        ]<br/>    <br/>        feature_service = FeatureService(<br/>            name=&quot;convrate_plus100&quot;,<br/>            features=[feature_views.driver[[&quot;conv_rate&quot;]], feature_views.driver_odfv],<br/>        )<br/>        feature_service_entity_mapping = FeatureService(<br/>            name=&quot;entity_mapping&quot;,<br/>            features=[<br/>                feature_views.location.with_name(&quot;origin&quot;).with_join_key_map(<br/>                    {&quot;location_id&quot;: &quot;origin_id&quot;}<br/>                ),<br/>                feature_views.location.with_name(&quot;destination&quot;).with_join_key_map(<br/>                    {&quot;location_id&quot;: &quot;destination_id&quot;}<br/>                ),<br/>            ],<br/>        )<br/>    <br/>&gt;       store.apply(<br/>            [<br/>                driver(),<br/>                customer(),<br/>                location(),<br/>                feature_service,<br/>                feature_service_entity_mapping,<br/>                *feature_views.values(),<br/>            ]<br/>        )<br/><br/>sdk/python/tests/integration/offline_store/test_universal_historical_retrieval.py:75: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffff82853310&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff67a31870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:32 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:32 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:32 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:=======&gt;                                                   (1 + 7) / 8]                                                                                [Stage 1:&gt;                                                          (0 + 8) / 8][Stage 1:=============================&gt;                             (4 + 4) / 8]                                                                                [Stage 2:=======&gt;                                                   (1 + 7) / 8][Stage 2:============================================&gt;              (6 + 2) / 8]                                                                                [Stage 3:======================&gt;                                    (3 + 5) / 8]                                                                                [Stage 5:&gt;                                                          (0 + 8) / 8][Stage 5:=============================&gt;                             (4 + 4) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/offline_store/test_universal_historical_retrieval.py::test_historical_features_persisting[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-True]</td>
          <td class="col-duration">7.61</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_0de993_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffffaa51bb50&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...ld_mapping=&lt;feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource object at 0xffffaa1d4df0&gt;))<br/>full_feature_names = True<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    @pytest.mark.parametrize(&quot;full_feature_names&quot;, [True, False], ids=lambda v: str(v))<br/>    def test_historical_features_persisting(<br/>        environment, universal_data_sources, full_feature_names<br/>    ):<br/>        store = environment.feature_store<br/>    <br/>        (entities, datasets, data_sources) = universal_data_sources<br/>        feature_views = construct_universal_feature_views(data_sources)<br/>    <br/>&gt;       store.apply([driver(), customer(), location(), *feature_views.values()])<br/><br/>sdk/python/tests/integration/offline_store/test_universal_historical_retrieval.py:359: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffffaa1d4910&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff8f5c1870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:31 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:31 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:======================&gt;                                    (3 + 5) / 8]                                                                                [Stage 1:&gt;                                                          (0 + 8) / 8][Stage 1:=============================&gt;                             (4 + 4) / 8]                                                                                [Stage 2:====================================&gt;                      (5 + 3) / 8]                                                                                [Stage 3:====================================&gt;                      (5 + 3) / 8]                                                                                [Stage 5:============================================&gt;              (6 + 2) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/offline_store/test_universal_historical_retrieval.py::test_historical_features_with_missing_request_data[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">7.85</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_7c00da_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffffa0a55c30&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...ld_mapping=&lt;feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource object at 0xffff66eab7f0&gt;))<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    def test_historical_features_with_missing_request_data(<br/>        environment, universal_data_sources<br/>    ):<br/>        store = environment.feature_store<br/>    <br/>        (_, datasets, data_sources) = universal_data_sources<br/>        feature_views = construct_universal_feature_views(data_sources)<br/>    <br/>&gt;       store.apply([driver(), customer(), location(), *feature_views.values()])<br/><br/>sdk/python/tests/integration/offline_store/test_universal_historical_retrieval.py:228: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffffa0a76cb0&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff89959870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 1:==============&gt;                                            (2 + 6) / 8][Stage 1:===================================================&gt;       (7 + 1) / 8]                                                                                [Stage 3:======================&gt;                                    (3 + 5) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/offline_store/test_universal_historical_retrieval.py::test_historical_features_persisting[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-False]</td>
          <td class="col-duration">7.71</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_d4577d_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffffaa7d59f0&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...ld_mapping=&lt;feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource object at 0xffffaa40d1e0&gt;))<br/>full_feature_names = False<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    @pytest.mark.parametrize(&quot;full_feature_names&quot;, [True, False], ids=lambda v: str(v))<br/>    def test_historical_features_persisting(<br/>        environment, universal_data_sources, full_feature_names<br/>    ):<br/>        store = environment.feature_store<br/>    <br/>        (entities, datasets, data_sources) = universal_data_sources<br/>        feature_views = construct_universal_feature_views(data_sources)<br/>    <br/>&gt;       store.apply([driver(), customer(), location(), *feature_views.values()])<br/><br/>sdk/python/tests/integration/offline_store/test_universal_historical_retrieval.py:359: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffffaa40c730&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff8f5c1870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:39 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:39 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:39 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:=======&gt;                                                   (1 + 7) / 8][Stage 0:====================================&gt;                      (5 + 3) / 8]                                                                                [Stage 2:=============================&gt;                             (4 + 4) / 8]                                                                                [Stage 3:=============================&gt;                             (4 + 4) / 8]                                                                                [Stage 4:===================================================&gt;       (7 + 1) / 8]                                                                                [Stage 5:============================================&gt;              (6 + 2) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/e2e/test_validation.py::test_logged_features_validation[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">26.78</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw2] linux -- Python 3.10.6 /usr/local/bin/python[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_a0edb9_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffff5867c670&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...ld_mapping=&lt;feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource object at 0xffff585cead0&gt;))<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    def test_logged_features_validation(environment, universal_data_sources):<br/>        store = environment.feature_store<br/>    <br/>        (_, datasets, data_sources) = universal_data_sources<br/>        feature_views = construct_universal_feature_views(data_sources)<br/>        feature_service = FeatureService(<br/>            name=&quot;test_service&quot;,<br/>            features=[<br/>                feature_views.customer[<br/>                    [&quot;current_balance&quot;, &quot;avg_passenger_count&quot;, &quot;lifetime_trip_count&quot;]<br/>                ],<br/>                feature_views.order[[&quot;order_is_success&quot;]],<br/>                feature_views.global_fv[[&quot;num_rides&quot;, &quot;avg_ride_length&quot;]],<br/>            ],<br/>            logging_config=LoggingConfig(<br/>                destination=environment.data_source_creator.create_logged_features_destination()<br/>            ),<br/>        )<br/>    <br/>&gt;       store.apply(<br/>            [driver(), customer(), location(), feature_service, *feature_views.values()]<br/>        )<br/><br/>sdk/python/tests/integration/e2e/test_validation.py:143: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffff9235b0a0&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff5ea45870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/08/12 14:51:30 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:30 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:30 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:51:30 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
22/08/12 14:51:30 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4044. Attempting port 4045.
22/08/12 14:51:30 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4045. Attempting port 4046.
22/08/12 14:51:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory
Scaling row group sizes to 95.00% for 8 writers
<br/> -----------------------------Captured stderr setup------------------------------ <br/>Warning: Ignoring non-Spark config property: master
Setting default log level to &quot;WARN&quot;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 1:&gt;                                                          (0 + 8) / 8][Stage 1:==============&gt;                                            (2 + 6) / 8]                                                                                [Stage 3:=======&gt;                                                   (1 + 7) / 8]                                                                                [Stage 4:=============================&gt;                             (4 + 4) / 8]                                                                                [Stage 5:=============================&gt;                             (4 + 4) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/registration/test_universal_odfv_feature_inference.py::test_infer_odfv_list_features[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False-False]</td>
          <td class="col-duration">0.02</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_d7291d_1&#x27;, test_repo_config=LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_f...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffffa0a83c70&gt;)<br/>infer_features = False, tmp_path = PosixPath(&#x27;/tmp/pytest-of-root/pytest-51/popen-gw3/test_infer_odfv_list_features_0&#x27;)<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.parametrize(&quot;infer_features&quot;, [True, False], ids=lambda v: str(v))<br/>    def test_infer_odfv_list_features(environment, infer_features, tmp_path):<br/>        fake_embedding = [1.0, 1.0]<br/>        items_df = pd.DataFrame(<br/>            data={<br/>                &quot;item_id&quot;: [0],<br/>                &quot;embedding_float&quot;: [fake_embedding],<br/>                &quot;embedding_double&quot;: [fake_embedding],<br/>                &quot;event_timestamp&quot;: [pd.Timestamp(datetime.utcnow())],<br/>                &quot;created&quot;: [pd.Timestamp(datetime.utcnow())],<br/>            }<br/>        )<br/>        output_path = f&quot;{tmp_path}/items.parquet&quot;<br/>        items_df.to_parquet(output_path)<br/>        fake_items_src = FileSource(<br/>            path=output_path,<br/>            timestamp_field=&quot;event_timestamp&quot;,<br/>            created_timestamp_column=&quot;created&quot;,<br/>        )<br/>        item_feature_view = create_item_embeddings_batch_feature_view(fake_items_src)<br/>        sim_odfv = similarity_feature_view(<br/>            [item_feature_view, create_similarity_request_source()],<br/>            infer_features=infer_features,<br/>        )<br/>        store = environment.feature_store<br/>&gt;       store.apply([item(), item_feature_view, sim_odfv])<br/><br/>sdk/python/tests/integration/registration/test_universal_odfv_feature_inference.py:70: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = similarity, features = [cos_double-Float64, cos_float-Float32], description = , tags = {},...uestSource object at 0xffffa0a82e30&gt;}, udf = &lt;function similarity at 0xffff89959990&gt;, udf_string = similarity raw udf)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/registration/test_universal_cli.py::test_odfv_apply[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">4.81</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw6] linux -- Python 3.10.6 /usr/local/bin/python[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_4167b7_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffffb8539930&gt;)<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    def test_odfv_apply(environment) -&gt; None:<br/>        project = f&quot;test_odfv_apply{str(uuid.uuid4()).replace(&#x27;-&#x27;, &#x27;&#x27;)[:8]}&quot;<br/>        runner = CliRunner()<br/>    <br/>        with tempfile.TemporaryDirectory() as repo_dir_name:<br/>            try:<br/>                repo_path = Path(repo_dir_name)<br/>                feature_store_yaml = make_feature_store_yaml(<br/>                    project, environment.test_repo_config, repo_path<br/>                )<br/>    <br/>                repo_config = repo_path / &quot;feature_store.yaml&quot;<br/>    <br/>                repo_config.write_text(dedent(feature_store_yaml))<br/>    <br/>                repo_example = repo_path / &quot;example.py&quot;<br/>                repo_example.write_text(get_example_repo(&quot;on_demand_feature_view_repo.py&quot;))<br/>                result = runner.run([&quot;apply&quot;], cwd=repo_path)<br/>&gt;               assertpy.assert_that(result.returncode).is_equal_to(0)<br/><span class="error">E               AssertionError: Expected &lt;1&gt; to be equal to &lt;0&gt;, but was not.</span><br/><br/>sdk/python/tests/integration/registration/test_universal_cli.py:133: AssertionError[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/offline_store/test_universal_historical_retrieval.py::test_historical_features_with_no_ttl[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-True]</td>
          <td class="col-duration">6.54</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_59584d_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffff444f5b10&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...ld_mapping=&lt;feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource object at 0xffff44eedc60&gt;))<br/>full_feature_names = True<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    @pytest.mark.parametrize(&quot;full_feature_names&quot;, [True, False], ids=lambda v: str(v))<br/>    def test_historical_features_with_no_ttl(<br/>        environment, universal_data_sources, full_feature_names<br/>    ):<br/>        store = environment.feature_store<br/>    <br/>        (entities, datasets, data_sources) = universal_data_sources<br/>        feature_views = construct_universal_feature_views(data_sources)<br/>    <br/>        # Remove ttls.<br/>        feature_views.customer.ttl = timedelta(seconds=0)<br/>        feature_views.order.ttl = timedelta(seconds=0)<br/>        feature_views.global_fv.ttl = timedelta(seconds=0)<br/>        feature_views.field_mapping.ttl = timedelta(seconds=0)<br/>    <br/>&gt;       store.apply([driver(), customer(), location(), *feature_views.values()])<br/><br/>sdk/python/tests/integration/offline_store/test_universal_historical_retrieval.py:444: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffff43992590&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff631c9870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:43 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:43 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:43 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:51:43 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
22/08/12 14:51:43 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4044. Attempting port 4045.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:============================================&gt;              (6 + 2) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/registration/test_universal_odfv_feature_inference.py::test_infer_odfv_features[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-True]</td>
          <td class="col-duration">5.18</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_b90041_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffff70f6fc40&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...ld_mapping=&lt;feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource object at 0xffff767bac80&gt;))<br/>infer_features = True<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    @pytest.mark.parametrize(&quot;infer_features&quot;, [True, False], ids=lambda v: str(v))<br/>    def test_infer_odfv_features(environment, universal_data_sources, infer_features):<br/>        store = environment.feature_store<br/>    <br/>        (entities, datasets, data_sources) = universal_data_sources<br/>    <br/>        driver_hourly_stats = create_driver_hourly_stats_batch_feature_view(<br/>            data_sources.driver<br/>        )<br/>        request_source = create_conv_rate_request_source()<br/>        driver_odfv = conv_rate_plus_100_feature_view(<br/>            [driver_hourly_stats, request_source],<br/>            infer_features=infer_features,<br/>        )<br/>    <br/>        feast_objects = [driver_hourly_stats, driver_odfv, driver(), customer()]<br/>&gt;       store.apply(feast_objects)<br/><br/>sdk/python/tests/integration/registration/test_universal_odfv_feature_inference.py:39: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffff768f9cc0&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff8f5c1870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:47 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:47 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 2:============================================&gt;              (6 + 2) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/registration/test_universal_odfv_feature_inference.py::test_infer_odfv_list_features[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False-True]</td>
          <td class="col-duration">0.02</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw6] linux -- Python 3.10.6 /usr/local/bin/python[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_b5379b_1&#x27;, test_repo_config=LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_f...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffffb857b4c0&gt;)<br/>infer_features = True, tmp_path = PosixPath(&#x27;/tmp/pytest-of-root/pytest-51/popen-gw6/test_infer_odfv_list_features_0&#x27;)<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.parametrize(&quot;infer_features&quot;, [True, False], ids=lambda v: str(v))<br/>    def test_infer_odfv_list_features(environment, infer_features, tmp_path):<br/>        fake_embedding = [1.0, 1.0]<br/>        items_df = pd.DataFrame(<br/>            data={<br/>                &quot;item_id&quot;: [0],<br/>                &quot;embedding_float&quot;: [fake_embedding],<br/>                &quot;embedding_double&quot;: [fake_embedding],<br/>                &quot;event_timestamp&quot;: [pd.Timestamp(datetime.utcnow())],<br/>                &quot;created&quot;: [pd.Timestamp(datetime.utcnow())],<br/>            }<br/>        )<br/>        output_path = f&quot;{tmp_path}/items.parquet&quot;<br/>        items_df.to_parquet(output_path)<br/>        fake_items_src = FileSource(<br/>            path=output_path,<br/>            timestamp_field=&quot;event_timestamp&quot;,<br/>            created_timestamp_column=&quot;created&quot;,<br/>        )<br/>        item_feature_view = create_item_embeddings_batch_feature_view(fake_items_src)<br/>        sim_odfv = similarity_feature_view(<br/>            [item_feature_view, create_similarity_request_source()],<br/>            infer_features=infer_features,<br/>        )<br/>        store = environment.feature_store<br/>&gt;       store.apply([item(), item_feature_view, sim_odfv])<br/><br/>sdk/python/tests/integration/registration/test_universal_odfv_feature_inference.py:70: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = similarity, features = [cos_double-Float64, cos_float-Float32], description = , tags = {},...uestSource object at 0xffffb857b910&gt;}, udf = &lt;function similarity at 0xffff97f4d990&gt;, udf_string = similarity raw udf)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/offline_store/test_universal_historical_retrieval.py::test_historical_features_with_no_ttl[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-False]</td>
          <td class="col-duration">6.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_f67cc8_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffff444ac970&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...ld_mapping=&lt;feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource object at 0xffff44bbaf20&gt;))<br/>full_feature_names = False<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    @pytest.mark.parametrize(&quot;full_feature_names&quot;, [True, False], ids=lambda v: str(v))<br/>    def test_historical_features_with_no_ttl(<br/>        environment, universal_data_sources, full_feature_names<br/>    ):<br/>        store = environment.feature_store<br/>    <br/>        (entities, datasets, data_sources) = universal_data_sources<br/>        feature_views = construct_universal_feature_views(data_sources)<br/>    <br/>        # Remove ttls.<br/>        feature_views.customer.ttl = timedelta(seconds=0)<br/>        feature_views.order.ttl = timedelta(seconds=0)<br/>        feature_views.global_fv.ttl = timedelta(seconds=0)<br/>        feature_views.field_mapping.ttl = timedelta(seconds=0)<br/>    <br/>&gt;       store.apply([driver(), customer(), location(), *feature_views.values()])<br/><br/>sdk/python/tests/integration/offline_store/test_universal_historical_retrieval.py:444: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffff447e9600&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff631c9870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:50 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:50 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:50 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:51:50 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
22/08/12 14:51:50 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4044. Attempting port 4045.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:====================================&gt;                      (5 + 3) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/offline_store/test_universal_historical_retrieval.py::test_historical_features[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-full:True]</td>
          <td class="col-duration">25.07</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw5] linux -- Python 3.10.6 /usr/local/bin/python[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_82c9cd_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffff56866830&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...ld_mapping=&lt;feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource object at 0xffff55ecf970&gt;))<br/>full_feature_names = True<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    @pytest.mark.parametrize(&quot;full_feature_names&quot;, [True, False], ids=lambda v: f&quot;full:{v}&quot;)<br/>    def test_historical_features(environment, universal_data_sources, full_feature_names):<br/>        store = environment.feature_store<br/>    <br/>        (entities, datasets, data_sources) = universal_data_sources<br/>    <br/>        feature_views = construct_universal_feature_views(data_sources)<br/>    <br/>        entity_df_with_request_data = datasets.entity_df.copy(deep=True)<br/>        entity_df_with_request_data[&quot;val_to_add&quot;] = [<br/>            i for i in range(len(entity_df_with_request_data))<br/>        ]<br/>        entity_df_with_request_data[&quot;driver_age&quot;] = [<br/>            i + 100 for i in range(len(entity_df_with_request_data))<br/>        ]<br/>    <br/>        feature_service = FeatureService(<br/>            name=&quot;convrate_plus100&quot;,<br/>            features=[feature_views.driver[[&quot;conv_rate&quot;]], feature_views.driver_odfv],<br/>        )<br/>        feature_service_entity_mapping = FeatureService(<br/>            name=&quot;entity_mapping&quot;,<br/>            features=[<br/>                feature_views.location.with_name(&quot;origin&quot;).with_join_key_map(<br/>                    {&quot;location_id&quot;: &quot;origin_id&quot;}<br/>                ),<br/>                feature_views.location.with_name(&quot;destination&quot;).with_join_key_map(<br/>                    {&quot;location_id&quot;: &quot;destination_id&quot;}<br/>                ),<br/>            ],<br/>        )<br/>    <br/>&gt;       store.apply(<br/>            [<br/>                driver(),<br/>                customer(),<br/>                location(),<br/>                feature_service,<br/>                feature_service_entity_mapping,<br/>                *feature_views.values(),<br/>            ]<br/>        )<br/><br/>sdk/python/tests/integration/offline_store/test_universal_historical_retrieval.py:75: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffff56864e50&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff794ad870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/08/12 14:51:44 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:44 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:44 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:51:44 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
22/08/12 14:51:44 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4044. Attempting port 4045.
22/08/12 14:51:44 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4045. Attempting port 4046.
22/08/12 14:51:44 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4046. Attempting port 4047.
22/08/12 14:51:54 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory
Scaling row group sizes to 95.00% for 8 writers
<br/> -----------------------------Captured stderr setup------------------------------ <br/>Warning: Ignoring non-Spark config property: master
Setting default log level to &quot;WARN&quot;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:======================&gt;                                    (3 + 5) / 8]                                                                                [Stage 1:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 2:&gt;                                                          (0 + 8) / 8][Stage 2:====================================&gt;                      (5 + 3) / 8]                                                                                [Stage 3:&gt;                                                          (0 + 8) / 8][Stage 3:===================================================&gt;       (7 + 1) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/integration/registration/test_universal_odfv_feature_inference.py::test_infer_odfv_features[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-False]</td>
          <td class="col-duration">2.58</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/><br/>environment = Environment(name=&#x27;integration_test_9ee21d_1&#x27;, test_repo_config=LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_...reator=&lt;tests.integration.feature_repos.universal.online_store.redis.RedisOnlineStoreCreator object at 0xffff8217d810&gt;)<br/>universal_data_sources = (UniversalEntities(customer_vals=[1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, ...ld_mapping=&lt;feast.infra.offline_stores.contrib.spark_offline_store.spark_source.SparkSource object at 0xffff82850ca0&gt;))<br/>infer_features = False<br/><br/>    @pytest.mark.integration<br/>    @pytest.mark.universal_offline_stores<br/>    @pytest.mark.parametrize(&quot;infer_features&quot;, [True, False], ids=lambda v: str(v))<br/>    def test_infer_odfv_features(environment, universal_data_sources, infer_features):<br/>        store = environment.feature_store<br/>    <br/>        (entities, datasets, data_sources) = universal_data_sources<br/>    <br/>        driver_hourly_stats = create_driver_hourly_stats_batch_feature_view(<br/>            data_sources.driver<br/>        )<br/>        request_source = create_conv_rate_request_source()<br/>        driver_odfv = conv_rate_plus_100_feature_view(<br/>            [driver_hourly_stats, request_source],<br/>            infer_features=infer_features,<br/>        )<br/>    <br/>        feast_objects = [driver_hourly_stats, driver_odfv, driver(), customer()]<br/>&gt;       store.apply(feast_objects)<br/><br/>sdk/python/tests/integration/registration/test_universal_odfv_feature_inference.py:39: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>sdk/python/feast/feature_store.py:873: in apply<br/>    self._registry.apply_feature_view(view, project=self.project, commit=False)<br/>sdk/python/feast/registry.py:1142: in apply_feature_view<br/>    feature_view_proto = feature_view.to_proto()<br/>/usr/local/lib/python3.10/site-packages/typeguard/__init__.py:1033: in wrapper<br/>    retval = func(*args, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;OnDemandFeatureView(name = conv_rate_plus_100, features = [conv_rate_plus_100-Float64, conv_rate_plus_val_to_add-Floa...Source object at 0xffff82852740&gt;}, udf = &lt;function conv_rate_plus_100 at 0xffff67a31870&gt;, udf_string = raw udf source)&gt;<br/><br/>    def to_proto(self) -&gt; OnDemandFeatureViewProto:<br/>        &quot;&quot;&quot;<br/>        Converts an on demand feature view object to its protobuf representation.<br/>    <br/>        Returns:<br/>            A OnDemandFeatureViewProto protobuf.<br/>        &quot;&quot;&quot;<br/>        meta = OnDemandFeatureViewMeta()<br/>        if self.created_timestamp:<br/>            meta.created_timestamp.FromDatetime(self.created_timestamp)<br/>        if self.last_updated_timestamp:<br/>            meta.last_updated_timestamp.FromDatetime(self.last_updated_timestamp)<br/>        sources = {}<br/>        for source_name, fv_projection in self.source_feature_view_projections.items():<br/>            sources[source_name] = OnDemandSource(<br/>                feature_view_projection=fv_projection.to_proto()<br/>            )<br/>        for (<br/>            source_name,<br/>            request_sources,<br/>        ) in self.source_request_sources.items():<br/>            sources[source_name] = OnDemandSource(<br/>                request_data_source=request_sources.to_proto()<br/>            )<br/>    <br/>        spec = OnDemandFeatureViewSpec(<br/>            name=self.name,<br/>            features=[feature.to_proto() for feature in self.features],<br/>            sources=sources,<br/>&gt;           user_defined_function=UserDefinedFunctionProto(<br/>                name=self.udf.__name__,<br/>                body=dill.dumps(self.udf, recurse=True),<br/>                body_text=self.udf_string,<br/>            ),<br/>            description=self.description,<br/>            tags=self.tags,<br/>            owner=self.owner,<br/>        )<br/><span class="error">E       ValueError: Protocol message UserDefinedFunction has no &quot;body_text&quot; field.</span><br/><br/>sdk/python/feast/on_demand_feature_view.py:203: ValueError[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/offline_store/test_universal_historical_retrieval.py::test_historical_features_with_entities_from_query[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-True]</td>
          <td class="col-duration">7.94</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw6] linux -- Python 3.10.6 /usr/local/bin/python[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/offline_store/test_universal_historical_retrieval.py&#x27;, 260, &#x27;Skipped: Offline source is not sql-based&#x27;)[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:31 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:==============&gt;                                            (2 + 6) / 8][Stage 0:===================================================&gt;       (7 + 1) / 8]                                                                                [Stage 1:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 3:&gt;                                                          (0 + 8) / 8][Stage 3:=======&gt;                                                   (1 + 7) / 8]                                                                                [Stage 5:==============&gt;                                            (2 + 6) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/offline_store/test_universal_historical_retrieval.py::test_historical_features_with_entities_from_query[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-False]</td>
          <td class="col-duration">7.86</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw6] linux -- Python 3.10.6 /usr/local/bin/python[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/offline_store/test_universal_historical_retrieval.py&#x27;, 260, &#x27;Skipped: Offline source is not sql-based&#x27;)[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:39 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:39 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:==============&gt;                                            (2 + 6) / 8][Stage 0:=============================&gt;                             (4 + 4) / 8]                                                                                [Stage 2:====================================&gt;                      (5 + 3) / 8]                                                                                [Stage 3:============================================&gt;              (6 + 2) / 8]                                                                                [Stage 4:=============================&gt;                             (4 + 4) / 8]                                                                                [Stage 5:===================================================&gt;       (7 + 1) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/offline_store/test_s3_custom_endpoint.py::test_registration_and_retrieval_from_custom_s3_endpoint[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/offline_store/test_s3_custom_endpoint.py&#x27;, 16, &#x27;Skipped: No way to run this test today. Credentials conflict with real AWS credentials in CI&#x27;)[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;int32&apos;, feature_is_list=True, has_empty_list=True)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;float&apos;, feature_is_list=True, has_empty_list=True)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;float&apos;, feature_is_list=True, has_empty_list=False)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;float&apos;, feature_is_list=False, has_empty_list=False)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;bool&apos;, feature_is_list=True, has_empty_list=True)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;bool&apos;, feature_is_list=True, has_empty_list=False)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;bool&apos;, feature_is_list=False, has_empty_list=False)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;datetime&apos;, feature_is_list=True, has_empty_list=True)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;datetime&apos;, feature_is_list=True, has_empty_list=False)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;datetime&apos;, feature_is_list=False, has_empty_list=False)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;int32&apos;, feature_is_list=True, has_empty_list=False)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;int64&apos;, feature_is_list=True, has_empty_list=True)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;int32&apos;, feature_is_list=False, has_empty_list=False)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;int64&apos;, feature_is_list=True, has_empty_list=False)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="skipped results-table-row">
        <tr>
          <td class="col-result">Skipped</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_online_features_types_match[TypeTestConfig(feature_dtype=&apos;int64&apos;, feature_is_list=False, has_empty_list=False)-environment0]</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/>(&#x27;/root/feast/sdk/python/tests/integration/registration/test_universal_types.py&#x27;, 135, &quot;Skipped: got empty parameter set [&#x27;environment&#x27;], function test_feature_get_online_features_types_match at /root/feast/sdk/python/tests/integration/registration/test_universal_types.py:134&quot;)[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/e2e/test_usage_e2e.py::test_usage_off</td>
          <td class="col-duration">0.13</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/e2e/test_usage_e2e.py::test_usage_on</td>
          <td class="col-duration">0.12</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw6] linux -- Python 3.10.6 /usr/local/bin/python[gw6] linux -- Python 3.10.6 /usr/local/bin/python[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/e2e/test_usage_e2e.py::test_exception_usage_off</td>
          <td class="col-duration">0.04</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/e2e/test_usage_e2e.py::test_exception_usage_on</td>
          <td class="col-duration">0.03</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/e2e/test_universal_e2e.py::test_e2e_consistency[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False-False]</td>
          <td class="col-duration">10.66</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw5] linux -- Python 3.10.6 /usr/local/bin/python[gw5] linux -- Python 3.10.6 /usr/local/bin/python[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/> ------------------------------Captured stdout call------------------------------ <br/>Materializing 1 feature views from 2022-08-12 09:51:10+00:00 to 2022-08-12 12:59:59+00:00 into the redis online store.

test_consistency_:
Materializing 1 feature views to 2022-08-12 14:51:10+00:00 into the redis online store.

test_consistency_ from 2022-08-12 12:59:59+00:00 to 2022-08-12 14:51:10+00:00:
<br/> ------------------------------Captured stderr call------------------------------ <br/>  0%|                                                                         | 0/2 [00:00&lt;?, ?it/s]100%|| 2/2 [00:00&lt;00:00, 950.34it/s]
  0%|                                                                         | 0/2 [00:00&lt;?, ?it/s]100%|| 2/2 [00:00&lt;00:00, 1500.11it/s]
<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/e2e/test_universal_e2e.py::test_e2e_consistency[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False-True]</td>
          <td class="col-duration">10.69</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw2] linux -- Python 3.10.6 /usr/local/bin/python[gw2] linux -- Python 3.10.6 /usr/local/bin/python[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/> ------------------------------Captured stdout call------------------------------ <br/>Materializing 1 feature views from 2022-08-12 09:51:10+00:00 to 2022-08-12 12:59:59+00:00 into the redis online store.

test_consistency_with_inference:
Materializing 1 feature views to 2022-08-12 14:51:10+00:00 into the redis online store.

test_consistency_with_inference from 2022-08-12 12:59:59+00:00 to 2022-08-12 14:51:10+00:00:
<br/> ------------------------------Captured stderr call------------------------------ <br/>  0%|                                                                         | 0/2 [00:00&lt;?, ?it/s]100%|| 2/2 [00:00&lt;00:00, 745.32it/s]
  0%|                                                                         | 0/2 [00:00&lt;?, ?it/s]100%|| 2/2 [00:00&lt;00:00, 94.14it/s]
<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/e2e/test_validation.py::test_e2e_validation_via_cli[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">17.49</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw5] linux -- Python 3.10.6 /usr/local/bin/python[gw5] linux -- Python 3.10.6 /usr/local/bin/python[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/> ------------------------------Captured stdout call------------------------------ <br/>Apply: stdout: b&#x27;No changes to registry\nNo changes to infrastructure\n&#x27;
 stderr: b&#x27;&#x27;
Apply: stdout: b&#x27;&#x27;
 stderr: b&#x27;&#x27;
<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/offline_store/test_offline_write.py::test_reorder_columns[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">21.18</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/08/12 14:51:14 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:14 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:14 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:51:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory
Scaling row group sizes to 95.00% for 8 writers
<br/> -----------------------------Captured stderr setup------------------------------ <br/>Warning: Ignoring non-Spark config property: master
Setting default log level to &quot;WARN&quot;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:=======&gt;                                                   (1 + 7) / 8]                                                                                [Stage 1:&gt;                                                          (0 + 8) / 8][Stage 1:=======&gt;                                                   (1 + 7) / 8]                                                                                [Stage 2:&gt;                                                          (0 + 8) / 8][Stage 2:=======&gt;                                                   (1 + 7) / 8]                                                                                [Stage 3:&gt;                                                          (0 + 8) / 8][Stage 3:======================&gt;                                    (3 + 5) / 8]                                                                                [Stage 5:&gt;                                                          (0 + 8) / 8][Stage 5:===================================================&gt;       (7 + 1) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>event_timestamp: timestamp[ns]
driver_id: int64
conv_rate: double
acc_rate: double
avg_daily_trips: int64
created: timestamp[ns]
----------------------------------------
event_timestamp: timestamp[us]
driver_id: int64
conv_rate: double
acc_rate: double
avg_daily_trips: int64
created: timestamp[us]
/tmp/tmpb7fn618b.parquet
<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/offline_store/test_offline_write.py::test_writing_incorrect_schema_fails[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">20.64</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/08/12 14:51:14 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:14 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory
Scaling row group sizes to 95.00% for 8 writers
<br/> -----------------------------Captured stderr setup------------------------------ <br/>Warning: Ignoring non-Spark config property: master
Setting default log level to &quot;WARN&quot;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 1:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 2:&gt;                                                          (0 + 8) / 8][Stage 2:=======&gt;                                                   (1 + 7) / 8]                                                                                [Stage 3:==============&gt;                                            (2 + 6) / 8]                                                                                [Stage 4:=============================&gt;                             (4 + 4) / 8][Stage 4:===================================================&gt;       (7 + 1) / 8]                                                                                [Stage 5:&gt;                                                          (0 + 8) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/offline_store/test_push_features_to_offline_store.py::test_push_features_and_read[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">31.81</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python[gw1] linux -- Python 3.10.6 /usr/local/bin/python[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/08/12 14:51:15 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:15 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:15 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:51:15 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
22/08/12 14:51:15 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4044. Attempting port 4045.
22/08/12 14:51:23 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory
Scaling row group sizes to 95.00% for 8 writers
<br/> -----------------------------Captured stderr setup------------------------------ <br/>Warning: Ignoring non-Spark config property: master
Setting default log level to &quot;WARN&quot;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 0:&gt;                                                          (0 + 1) / 8][Stage 0:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 1:&gt;                                                          (0 + 8) / 8][Stage 1:==============&gt;                                            (2 + 6) / 8]                                                                                [Stage 2:=======&gt;                                                   (1 + 7) / 8][Stage 2:======================&gt;                                    (3 + 5) / 8]                                                                                [Stage 3:=======&gt;                                                   (1 + 7) / 8][Stage 3:============================================&gt;              (6 + 2) / 8]                                                                                [Stage 5:======================&gt;                                    (3 + 5) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>event_timestamp: timestamp[ns]
location_id: int64
temperature: int64
created: timestamp[ns]
----------------------------------------
event_timestamp: timestamp[us]
location_id: int64
temperature: int64
created: timestamp[us]
/tmp/tmpfv4woroi.parquet
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 7:&gt;                                                          (0 + 8) / 8][Stage 7:=============================&gt;                             (4 + 4) / 8][Stage 7:===================================================&gt;       (7 + 1) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/offline_store/test_universal_historical_retrieval.py::test_historical_features_with_shared_batch_source[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-False]</td>
          <td class="col-duration">7.94</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 1:=======&gt;                                                   (1 + 7) / 8][Stage 1:====================================&gt;                      (5 + 3) / 8]                                                                                [Stage 2:&gt;                                                          (0 + 8) / 8][Stage 2:====================================&gt;                      (5 + 3) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/offline_store/test_offline_write.py::test_writing_consecutively_to_offline_store[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">21.97</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw0] linux -- Python 3.10.6 /usr/local/bin/python[gw0] linux -- Python 3.10.6 /usr/local/bin/python[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:33 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:33 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:33 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:51:33 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:===================================================&gt;       (7 + 1) / 8]                                                                                [Stage 1:&gt;                                                          (0 + 8) / 8][Stage 1:======================&gt;                                    (3 + 5) / 8]                                                                                [Stage 2:============================================&gt;              (6 + 2) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>event_timestamp: timestamp[ns]
driver_id: int64
conv_rate: float
acc_rate: float
avg_daily_trips: int64
created: timestamp[ns]
----------------------------------------
event_timestamp: timestamp[us]
driver_id: int64
conv_rate: double
acc_rate: double
avg_daily_trips: int64
created: timestamp[us]
/tmp/tmpzfa9rqmu.parquet
After:    driver_id            event_timestamp  conv_rate  acc_rate  avg_daily_trips
0       1001 2022-08-12 17:51:39.971960   0.059460  0.144071                7
1       1001 2022-08-12 18:51:39.971960   0.086223  0.076532                6
First:              event_timestamp  ...                    created
0 2022-08-12 17:51:39.971960  ... 2022-08-12 14:51:39.971960
1 2022-08-12 18:51:39.971960  ... 2022-08-12 14:51:39.971960

[2 rows x 6 columns]
After: 0    0.059460
1    0.086223
Name: conv_rate, dtype: float64
First: 0    0.059460
1    0.086223
Name: conv_rate, dtype: float32
event_timestamp: timestamp[ns]
driver_id: int64
conv_rate: float
acc_rate: float
avg_daily_trips: int64
created: timestamp[ns]
----------------------------------------
event_timestamp: timestamp[us]
driver_id: int64
conv_rate: double
acc_rate: double
avg_daily_trips: int64
created: timestamp[us]
/tmp/tmperwakxny.parquet
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 8:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 44:===============&gt;  (7 + 1) / 8][Stage 45:==&gt;               (1 + 7) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/offline_store/test_universal_historical_retrieval.py::test_historical_features_with_shared_batch_source[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-True]</td>
          <td class="col-duration">7.24</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:39 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:==============&gt;                                            (2 + 6) / 8][Stage 0:=============================&gt;                             (4 + 4) / 8]                                                                                [Stage 1:&gt;                                                          (0 + 8) / 8][Stage 1:====================================&gt;                      (5 + 3) / 8]                                                                                [Stage 3:===================================================&gt;       (7 + 1) / 8]                                                                                [Stage 4:============================================&gt;              (6 + 2) / 8]                                                                                [Stage 5:====================================&gt;                      (5 + 3) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/online_store/test_universal_online.py::test_online_retrieval_with_event_timestamps[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False-True]</td>
          <td class="col-duration">0.16</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_feature_store.py::test_feature_view_inference_success[simple_dataset_1-feature_store_with_local_registry]</td>
          <td class="col-duration">0.03</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_inference.py::test_update_file_data_source_with_inferred_event_timestamp_col</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_inference.py::test_update_data_sources_with_inferred_event_timestamp_col[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">0.24</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/online_store/test_universal_online.py::test_write_to_online_store[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">0.20</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/online_store/test_universal_online.py::test_online_store_cleanup[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">0.33</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/> ------------------------------Captured stdout call------------------------------ <br/>Materializing 2 feature views from 2022-08-08 14:00:00+00:00 to 2022-08-13 14:00:00+00:00 into the redis online store.

test_universal_online_simple_driver:
driver_stats:
<br/> ------------------------------Captured stderr call------------------------------ <br/>  0%|                                                                        | 0/19 [00:00&lt;?, ?it/s]100%|| 19/19 [00:00&lt;00:00, 6363.63it/s]
  0%|                                                                        | 0/19 [00:00&lt;?, ?it/s]100%|| 19/19 [00:00&lt;00:00, 8224.13it/s]
<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/online_store/test_universal_online.py::test_online_retrieval_with_event_timestamps[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False-False]</td>
          <td class="col-duration">0.26</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw6] linux -- Python 3.10.6 /usr/local/bin/python[gw6] linux -- Python 3.10.6 /usr/local/bin/python[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/online_store/test_universal_online.py::test_online_retrieval_with_shared_batch_source[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">0.13</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_cli.py::test_universal_cli[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">39.37</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python[gw7] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:47 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_entity_inference_types_match[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-Int32]</td>
          <td class="col-duration">2.60</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:48 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:48 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:48 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:=======&gt;                                                   (1 + 7) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_entity_inference_types_match[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-String]</td>
          <td class="col-duration">3.09</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw2] linux -- Python 3.10.6 /usr/local/bin/python[gw2] linux -- Python 3.10.6 /usr/local/bin/python[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:48 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:48 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:48 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:51:48 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
22/08/12 14:51:48 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4044. Attempting port 4045.
22/08/12 14:51:48 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4045. Attempting port 4046.
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:==============&gt;                                            (2 + 6) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_entity_inference_types_match[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False-Int64]</td>
          <td class="col-duration">2.57</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:51 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:51 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:51 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:=============================&gt;                             (4 + 4) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_odfv_feature_inference.py::test_infer_odfv_features_with_error[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">0.28</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;int32&apos;, feature_is_list=True, has_empty_list=True)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">15.66</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw2] linux -- Python 3.10.6 /usr/local/bin/python[gw2] linux -- Python 3.10.6 /usr/local/bin/python[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:51 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:51 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:51 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:51:51 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
22/08/12 14:51:51 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4044. Attempting port 4045.
22/08/12 14:51:51 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4045. Attempting port 4046.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:=======&gt;                                                   (1 + 7) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts value
0          1 2022-08-12 10:51:53.725    []
1          3 2022-08-12 12:51:53.725    []
Asserting historical feature list types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: list&lt;element: int64&gt;
  child 0, element: int64
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:51:53.725000000,2022-08-12 12:51:53.725000000]]
value: [[[],[]]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: array (nullable = true)
 |    |-- element: long (containsNull = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value                object
dtype: object
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 2:===================================================&gt;       (7 + 1) / 8][Stage 3:=========&gt;                                                 (1 + 5) / 6][Stage 4:=============================&gt;                             (3 + 3) / 6]                                                                                [Stage 22:&gt;                                                         (0 + 1) / 1]                                                                                [Stage 41:==============&gt;                                           (2 + 6) / 8][Stage 42:=======&gt;                                                  (1 + 7) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;int32&apos;, feature_is_list=False, has_empty_list=False)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">17.16</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:53 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:53 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:==============&gt;                                            (2 + 6) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts  value
0          1 2022-08-12 10:51:55.185      1
1          3 2022-08-12 12:51:55.185      4
Asserting historical feature types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: int64
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:51:55.185000000,2022-08-12 12:51:55.185000000]]
value: [[1,4]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: long (nullable = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value                 int64
dtype: object
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 2:======&gt;            (2 + 4) / 6][Stage 3:=======&gt;           (3 + 4) / 8]                                                                                [Stage 45:==&gt;               (1 + 7) / 8][Stage 46:===&gt;              (1 + 1) / 6][Stage 45:===============&gt;  (7 + 1) / 8][Stage 46:===============&gt;  (5 + 1) / 6]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/offline_store/test_universal_historical_retrieval.py::test_historical_features_from_bigquery_sources_containing_backfills[LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">5.70</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw0] linux -- Python 3.10.6 /usr/local/bin/python[gw0] linux -- Python 3.10.6 /usr/local/bin/python[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:55 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:55 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:55 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:51:55 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
<br/> ------------------------------Captured stdout call------------------------------ <br/>actual_df shape: (2, 3)
Time to execute job_from_df.to_df() = &#x27;0:00:02.627909&#x27;

<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:==============&gt;                                            (2 + 6) / 8]                                                                                [Stage 4:=============================&gt;                             (4 + 4) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;int64&apos;, feature_is_list=False, has_empty_list=False)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">16.05</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:===================================================&gt;       (7 + 1) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts  value
0          1 2022-08-12 10:51:55.409      1
1          3 2022-08-12 12:51:55.409      4
Asserting historical feature types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: int64
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:51:55.409000000,2022-08-12 12:51:55.409000000]]
value: [[1,4]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: long (nullable = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value                 int64
dtype: object
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 3:&gt;                                                          (0 + 6) / 6]                                                                                [Stage 28:&gt;                                                         (0 + 8) / 8]                                                                                [Stage 53:==================(8 + 0) / 8][Stage 54:==================(8 + 0) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;int64&apos;, feature_is_list=True, has_empty_list=False)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">18.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw6] linux -- Python 3.10.6 /usr/local/bin/python[gw6] linux -- Python 3.10.6 /usr/local/bin/python[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:53 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:53 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:53 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:=======&gt;                                                   (1 + 7) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts   value
0          1 2022-08-12 10:51:55.429  [1, 1]
1          3 2022-08-12 12:51:55.429  [4, 4]
Asserting historical feature list types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: list&lt;element: int64&gt;
  child 0, element: int64
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:51:55.429000000,2022-08-12 12:51:55.429000000]]
value: [[[1,1],[4,4]]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: array (nullable = true)
 |    |-- element: long (containsNull = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value                object
dtype: object
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 2:&gt;                                                          (0 + 8) / 8][Stage 2:====&gt;              (2 + 6) / 8][Stage 3:&gt;                  (0 + 3) / 6]                                                                                [Stage 27:===============&gt;  (7 + 1) / 8][Stage 28:======&gt;           (3 + 5) / 8]                                                                                [Stage 45:=========&gt;        (4 + 4) / 8][Stage 46:&gt;                 (0 + 8) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;int32&apos;, feature_is_list=True, has_empty_list=False)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">11.96</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python[gw1] linux -- Python 3.10.6 /usr/local/bin/python[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:51:56 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:51:56 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:51:56 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:51:56 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
22/08/12 14:51:56 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4044. Attempting port 4045.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:===================================================&gt;       (7 + 1) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts   value
0          1 2022-08-12 10:51:58.597  [1, 1]
1          3 2022-08-12 12:51:58.597  [4, 4]
Asserting historical feature list types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: list&lt;element: int64&gt;
  child 0, element: int64
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:51:58.597000000,2022-08-12 12:51:58.597000000]]
value: [[[1,1],[4,4]]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: array (nullable = true)
 |    |-- element: long (containsNull = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value                object
dtype: object
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 2:=========&gt;         (4 + 4) / 8][Stage 3:&gt;                  (0 + 5) / 8][Stage 3:=======&gt;                                                   (1 + 7) / 8][Stage 3:============================================&gt;              (6 + 2) / 8]                                                                                [Stage 38:===&gt;(6 + 2) / 8][Stage 39:&gt;   (1 + 6) / 8][Stage 40:&gt;   (0 + 0) / 6]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/online_store/test_push_features_to_online_store.py::test_push_features_and_read[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">0.25</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw0] linux -- Python 3.10.6 /usr/local/bin/python[gw0] linux -- Python 3.10.6 /usr/local/bin/python[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;bool&apos;, feature_is_list=True, has_empty_list=False)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">9.92</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw0] linux -- Python 3.10.6 /usr/local/bin/python[gw0] linux -- Python 3.10.6 /usr/local/bin/python[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:52:01 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:52:01 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:52:01 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:52:01 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:==============&gt;                                            (2 + 6) / 8][Stage 0:===================================================&gt;       (7 + 1) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts         value
0          1 2022-08-12 10:52:03.025  [True, True]
1          3 2022-08-12 12:52:03.025  [True, True]
Asserting historical feature list types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: list&lt;element: bool&gt;
  child 0, element: bool
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:52:03.025000000,2022-08-12 12:52:03.025000000]]
value: [[[true,true],[true,true]]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: array (nullable = true)
 |    |-- element: boolean (containsNull = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value                object
dtype: object
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 2:==============&gt;                                            (2 + 6) / 8][Stage 3:==============&gt;                                            (2 + 6) / 8][Stage 3:====================================&gt;                      (5 + 3) / 8]                                                                                [Stage 41:===========================================&gt;              (6 + 2) / 8][Stage 42:===============&gt;  (7 + 1) / 8][Stage 43:============&gt;     (4 + 2) / 6]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/online_store/test_universal_online.py::test_entity_ttl_online_store[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">1.33</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw5] linux -- Python 3.10.6 /usr/local/bin/python[gw5] linux -- Python 3.10.6 /usr/local/bin/python[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/online_store/test_universal_online.py::test_write_to_online_store_event_check[LOCAL:File:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">0.12</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw5] linux -- Python 3.10.6 /usr/local/bin/python[gw5] linux -- Python 3.10.6 /usr/local/bin/python[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/> ------------------------------Captured stdout call------------------------------ <br/>Materializing 1 feature views from 2022-08-12 02:52:05+00:00 to 2022-08-12 14:52:05+00:00 into the redis online store.

feature_view_123:
<br/> ------------------------------Captured stderr call------------------------------ <br/>  0%|                                                                         | 0/3 [00:00&lt;?, ?it/s]100%|| 3/3 [00:00&lt;00:00, 4105.35it/s]
<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;datetime&apos;, feature_is_list=True, has_empty_list=True)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">17.57</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw5] linux -- Python 3.10.6 /usr/local/bin/python[gw5] linux -- Python 3.10.6 /usr/local/bin/python[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:52:06 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:52:06 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:52:06 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:52:06 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
22/08/12 14:52:06 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4044. Attempting port 4045.
22/08/12 14:52:06 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4045. Attempting port 4046.
22/08/12 14:52:06 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4046. Attempting port 4047.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:======================&gt;                                    (3 + 5) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts value
0          1 2022-08-12 10:52:08.628    []
1          3 2022-08-12 12:52:08.628    []
Asserting historical feature list types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: list&lt;element: timestamp[ns]&gt;
  child 0, element: timestamp[ns]
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:52:08.628000000,2022-08-12 12:52:08.628000000]]
value: [[[],[]]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: array (nullable = true)
 |    |-- element: timestamp (containsNull = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value                object
dtype: object
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 2:&gt;                                                          (0 + 8) / 8]                                                                                [Stage 5:&gt;                  (0 + 8) / 8][Stage 6:&gt;                  (0 + 0) / 6][Stage 6:&gt;                                                          (0 + 6) / 6]                                                                                [Stage 8:&gt;                                                          (0 + 1) / 1]                                                                                [Stage 22:&gt;                                                         (0 + 8) / 8][Stage 22:=============&gt;    (6 + 2) / 8][Stage 23:&gt;                 (0 + 0) / 8][Stage 23:&gt;                 (0 + 8) / 8][Stage 24:&gt;                 (0 + 0) / 6]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;int64&apos;, feature_is_list=True, has_empty_list=True)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">10.53</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw2] linux -- Python 3.10.6 /usr/local/bin/python[gw2] linux -- Python 3.10.6 /usr/local/bin/python[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:52:07 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:52:07 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:52:07 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:52:07 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
22/08/12 14:52:07 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4044. Attempting port 4045.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:==============&gt;                                            (2 + 6) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts value
0          1 2022-08-12 10:52:09.394    []
1          3 2022-08-12 12:52:09.394    []
Asserting historical feature list types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: list&lt;element: int64&gt;
  child 0, element: int64
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:52:09.394000000,2022-08-12 12:52:09.394000000]]
value: [[[],[]]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: array (nullable = true)
 |    |-- element: long (containsNull = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value                object
dtype: object
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 20:==&gt; (4 + 4) / 8][Stage 21:&gt;   (0 + 4) / 8][Stage 22:&gt;   (0 + 0) / 6][Stage 21:====&gt;             (2 + 6) / 8][Stage 22:&gt;                 (0 + 2) / 6]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;bool&apos;, feature_is_list=True, has_empty_list=True)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">11.62</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw1] linux -- Python 3.10.6 /usr/local/bin/python[gw1] linux -- Python 3.10.6 /usr/local/bin/python[gw1] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:52:08 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:52:08 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:52:08 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:52:08 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
22/08/12 14:52:08 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4044. Attempting port 4045.
22/08/12 14:52:08 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4045. Attempting port 4046.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts value
0          1 2022-08-12 10:52:10.403    []
1          3 2022-08-12 12:52:10.403    []
Asserting historical feature list types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: list&lt;element: bool&gt;
  child 0, element: bool
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:52:10.403000000,2022-08-12 12:52:10.403000000]]
value: [[[],[]]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: array (nullable = true)
 |    |-- element: boolean (containsNull = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value                object
dtype: object
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 2:===================================================&gt;       (7 + 1) / 8]                                                                                [Stage 19:=======&gt;                                                  (1 + 7) / 8][Stage 19:=&gt;  (3 + 5) / 8][Stage 20:&gt;   (0 + 3) / 8][Stage 21:&gt;   (0 + 0) / 6][Stage 19:===&gt;(7 + 1) / 8][Stage 20:=&gt;  (2 + 6) / 8][Stage 21:==&gt; (3 + 1) / 6]                                                                                [Stage 44:===============&gt;  (7 + 1) / 8][Stage 45:&gt;                 (0 + 7) / 8][Stage 44:===&gt;(7 + 1) / 8][Stage 45:==&gt; (5 + 3) / 8][Stage 46:==&gt; (4 + 2) / 6]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;float&apos;, feature_is_list=True, has_empty_list=True)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">11.31</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python[gw4] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:==============&gt;                                            (2 + 6) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts value
0          1 2022-08-12 10:52:11.632    []
1          3 2022-08-12 12:52:11.632    []
Asserting historical feature list types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: list&lt;element: double&gt;
  child 0, element: double
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:52:11.632000000,2022-08-12 12:52:11.632000000]]
value: [[[],[]]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: array (nullable = true)
 |    |-- element: double (containsNull = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value                object
dtype: object
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 3:=============================&gt;                             (4 + 4) / 8][Stage 3:===================================================&gt;       (7 + 1) / 8]                                                                                [Stage 21:======================================&gt;                   (4 + 2) / 6]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;float&apos;, feature_is_list=True, has_empty_list=False)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">10.88</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python[gw3] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:52:10 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:52:10 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:============================================&gt;              (6 + 2) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts       value
0          1 2022-08-12 10:52:12.428  [1.0, 1.0]
1          3 2022-08-12 12:52:12.428  [4.0, 4.0]
Asserting historical feature list types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: list&lt;element: double&gt;
  child 0, element: double
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:52:12.428000000,2022-08-12 12:52:12.428000000]]
value: [[[1,1],[4,4]]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: array (nullable = true)
 |    |-- element: double (containsNull = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value                object
dtype: object
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 2:====================================&gt;                      (5 + 3) / 8][Stage 3:=&gt;   (3 + 5) / 8][Stage 4:&gt;    (0 + 3) / 6][Stage 5:&gt;    (0 + 0) / 6][Stage 4:&gt;                  (0 + 6) / 6][Stage 5:===&gt;               (1 + 2) / 6]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;bool&apos;, feature_is_list=False, has_empty_list=False)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">10.25</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw0] linux -- Python 3.10.6 /usr/local/bin/python[gw0] linux -- Python 3.10.6 /usr/local/bin/python[gw0] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:52:11 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:52:11 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:52:11 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:==============&gt;                                            (2 + 6) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts  value
0          1 2022-08-12 10:52:13.005   True
1          3 2022-08-12 12:52:13.005   True
Asserting historical feature types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: bool
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:52:13.005000000,2022-08-12 12:52:13.005000000]]
value: [[true,true]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: boolean (nullable = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value                  bool
dtype: object
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 3:===================================================&gt;       (7 + 1) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;float&apos;, feature_is_list=False, has_empty_list=False)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">10.89</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw6] linux -- Python 3.10.6 /usr/local/bin/python[gw6] linux -- Python 3.10.6 /usr/local/bin/python[gw6] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:52:11 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:52:11 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:52:11 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:52:11 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:=======&gt;                                                   (1 + 7) / 8][Stage 0:==============&gt;                                            (2 + 6) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts  value
0          1 2022-08-12 10:52:14.128    1.0
1          3 2022-08-12 12:52:14.128    4.0
Asserting historical feature types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: double
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:52:14.128000000,2022-08-12 12:52:14.128000000]]
value: [[1,4]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: double (nullable = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value               float64
dtype: object
<br/> ------------------------------Captured stderr call------------------------------ <br/>[Stage 2:=======&gt;           (3 + 5) / 8][Stage 3:==&gt;                (1 + 3) / 8][Stage 3:=============================&gt;                             (4 + 4) / 8]                                                                                <br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;datetime&apos;, feature_is_list=False, has_empty_list=False)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">6.50</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw2] linux -- Python 3.10.6 /usr/local/bin/python[gw2] linux -- Python 3.10.6 /usr/local/bin/python[gw2] linux -- Python 3.10.6 /usr/local/bin/python<br/> -----------------------------Captured stdout setup------------------------------ <br/>22/08/12 14:52:18 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4040. Attempting port 4041.
22/08/12 14:52:18 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4041. Attempting port 4042.
22/08/12 14:52:18 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4042. Attempting port 4043.
22/08/12 14:52:18 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4043. Attempting port 4044.
22/08/12 14:52:18 WARN Utils: Service &#x27;SparkUI&#x27; could not bind on port 4044. Attempting port 4045.
<br/> -----------------------------Captured stderr setup------------------------------ <br/>[Stage 0:&gt;                                                          (0 + 8) / 8][Stage 0:====================================&gt;                      (5 + 3) / 8]                                                                                <br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id                      ts      value
0          1 2022-08-12 10:52:20.084 1980-01-01
1          3 2022-08-12 12:52:20.084 1982-01-01
Asserting historical feature types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: timestamp[ns]
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:52:20.084000000,2022-08-12 12:52:20.084000000]]
value: [[1980-01-01 00:00:00.000000000,1982-01-01 00:00:00.000000000]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: timestamp (nullable = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value        datetime64[ns]
dtype: object
<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/integration/registration/test_universal_types.py::test_feature_get_historical_features_types_match[TypeTestConfig(feature_dtype=&apos;datetime&apos;, feature_is_list=True, has_empty_list=False)-LOCAL:Spark:RedisOnlineStoreCreator:python_fs:False:go_fs:False]</td>
          <td class="col-duration">3.97</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/>[gw5] linux -- Python 3.10.6 /usr/local/bin/python[gw5] linux -- Python 3.10.6 /usr/local/bin/python[gw5] linux -- Python 3.10.6 /usr/local/bin/python<br/> ------------------------------Captured stdout call------------------------------ <br/>Using ts as the event timestamp. To specify a column explicitly, please name it event_timestamp.
   driver_id  ...                                       value
0          1  ...  [1980-01-01 00:00:00, 1980-01-01 00:00:00]
1          3  ...  [1982-01-01 00:00:00, 1982-01-01 00:00:00]

[2 rows x 3 columns]
Asserting historical feature list types
Asserting historical feature arrow types
pyarrow.Table
driver_id: int64
ts: timestamp[ns]
value: list&lt;element: timestamp[ns]&gt;
  child 0, element: timestamp[ns]
----
driver_id: [[1,3]]
ts: [[2022-08-12 10:52:24.149000000,2022-08-12 12:52:24.149000000]]
value: [[[1980-01-01 00:00:00.000000000,1980-01-01 00:00:00.000000000],[1982-01-01 00:00:00.000000000,1982-01-01 00:00:00.000000000]]]
Spark schema:
root
 |-- driver_id: long (nullable = true)
 |-- ts: timestamp (nullable = true)
 |-- value: array (nullable = true)
 |    |-- element: timestamp (containsNull = true)

None
Pandas schema:
driver_id             int64
ts           datetime64[ns]
value                object
dtype: object
<br/></div></td></tr></tbody></table></body></html>